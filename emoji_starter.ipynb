{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMOJI PREDICTION CHALLENGE: Modelling Walkthrough\n",
    "\n",
    "This notebook is a starter example of developing a model to predict Emojis from Twitter data\n",
    "- Tweet & emoji data exploration\n",
    "- NLP preprocessing\n",
    "- GBMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## preprocess.py should have created a test.csv and train.csv \n",
    "## - make sure they are in the same directory as this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_FNAME = 'train.csv'\n",
    "TWEET_COL = 'text'\n",
    "EMOJI_COL = 'emoticons'\n",
    "\n",
    "df = pd.read_csv(DATA_FNAME)\n",
    "df = df[['tweet_id', TWEET_COL, EMOJI_COL]]\n",
    "df = df[df[EMOJI_COL].apply(type) == str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exporation\n",
    "### Look at some general views of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emoticons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1433932</td>\n",
       "      <td>@AmazonHelp Prime shipping is useless since ev...</td>\n",
       "      <td>[':face_with_tears_of_joy:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1175287</td>\n",
       "      <td>@118625 This is the 2nd time from a different ...</td>\n",
       "      <td>[':angry_face:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1929034</td>\n",
       "      <td>@116062 where are all your curly hair products...</td>\n",
       "      <td>[':thinking_face:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2852186</td>\n",
       "      <td>@792994 Olá, Idris! É difícil se resistir, não...</td>\n",
       "      <td>[':thinking_face:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007969</td>\n",
       "      <td>@593759 Thanks for the suggestion, Dijonay! We...</td>\n",
       "      <td>[':green_heart:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>997293</td>\n",
       "      <td>how do u cancel an uber eats order i accidenta...</td>\n",
       "      <td>[':face_with_tears_of_joy:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2114182</td>\n",
       "      <td>@623333 Hey Naina! We're launching regularly i...</td>\n",
       "      <td>[':green_heart:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1559747</td>\n",
       "      <td>@GWRHelp If service is displaying as 4minutes ...</td>\n",
       "      <td>[':face_with_rolling_eyes:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1701953</td>\n",
       "      <td>@115858 can make brand new phone with all thes...</td>\n",
       "      <td>[':face_with_rolling_eyes:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1481022</td>\n",
       "      <td>@282263 Hi there Are you wanting to order a re...</td>\n",
       "      <td>[':thumbs_down:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>924743</td>\n",
       "      <td>Great start to our honeymoon. Thanks @American...</td>\n",
       "      <td>[':thumbs_down:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>280292</td>\n",
       "      <td>@182802 @115766 My disc got scratched by my 3 ...</td>\n",
       "      <td>[':face_with_rolling_eyes:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1787207</td>\n",
       "      <td>@115937, your customer service sucks!</td>\n",
       "      <td>[':angry_face:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1016458</td>\n",
       "      <td>@Delta I have a connecting flight</td>\n",
       "      <td>[':thumbs_down:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1672446</td>\n",
       "      <td>@116827 y'all sent my card off yet or nahh, I ...</td>\n",
       "      <td>[':face_with_tears_of_joy:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2099107</td>\n",
       "      <td>When you get excited for freebies in your food...</td>\n",
       "      <td>[':face_with_rolling_eyes:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1313552</td>\n",
       "      <td>@426882 @115911 She probably won't reply until...</td>\n",
       "      <td>[':face_with_rolling_eyes:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2937337</td>\n",
       "      <td>Airbnb host cancelled within 36 hours of my tr...</td>\n",
       "      <td>[':thinking_face:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>802229</td>\n",
       "      <td>@sainsburys Thank you ️</td>\n",
       "      <td>[':smiling_face:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>626294</td>\n",
       "      <td>@ATVIAssist @ATVIAssist sometimes I lag so bad...</td>\n",
       "      <td>[':face_with_tears_of_joy:']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text  \\\n",
       "0   1433932  @AmazonHelp Prime shipping is useless since ev...   \n",
       "1   1175287  @118625 This is the 2nd time from a different ...   \n",
       "2   1929034  @116062 where are all your curly hair products...   \n",
       "3   2852186  @792994 Olá, Idris! É difícil se resistir, não...   \n",
       "4   2007969  @593759 Thanks for the suggestion, Dijonay! We...   \n",
       "5    997293  how do u cancel an uber eats order i accidenta...   \n",
       "6   2114182  @623333 Hey Naina! We're launching regularly i...   \n",
       "7   1559747  @GWRHelp If service is displaying as 4minutes ...   \n",
       "8   1701953  @115858 can make brand new phone with all thes...   \n",
       "9   1481022  @282263 Hi there Are you wanting to order a re...   \n",
       "10   924743  Great start to our honeymoon. Thanks @American...   \n",
       "11   280292  @182802 @115766 My disc got scratched by my 3 ...   \n",
       "12  1787207             @115937, your customer service sucks!    \n",
       "13  1016458                 @Delta I have a connecting flight    \n",
       "14  1672446  @116827 y'all sent my card off yet or nahh, I ...   \n",
       "15  2099107  When you get excited for freebies in your food...   \n",
       "16  1313552  @426882 @115911 She probably won't reply until...   \n",
       "17  2937337  Airbnb host cancelled within 36 hours of my tr...   \n",
       "18   802229                            @sainsburys Thank you ️   \n",
       "19   626294  @ATVIAssist @ATVIAssist sometimes I lag so bad...   \n",
       "\n",
       "                       emoticons  \n",
       "0   [':face_with_tears_of_joy:']  \n",
       "1               [':angry_face:']  \n",
       "2            [':thinking_face:']  \n",
       "3            [':thinking_face:']  \n",
       "4              [':green_heart:']  \n",
       "5   [':face_with_tears_of_joy:']  \n",
       "6              [':green_heart:']  \n",
       "7   [':face_with_rolling_eyes:']  \n",
       "8   [':face_with_rolling_eyes:']  \n",
       "9              [':thumbs_down:']  \n",
       "10             [':thumbs_down:']  \n",
       "11  [':face_with_rolling_eyes:']  \n",
       "12              [':angry_face:']  \n",
       "13             [':thumbs_down:']  \n",
       "14  [':face_with_tears_of_joy:']  \n",
       "15  [':face_with_rolling_eyes:']  \n",
       "16  [':face_with_rolling_eyes:']  \n",
       "17           [':thinking_face:']  \n",
       "18            [':smiling_face:']  \n",
       "19  [':face_with_tears_of_joy:']  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emoticons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29713</td>\n",
       "      <td>29713</td>\n",
       "      <td>29713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>29713</td>\n",
       "      <td>29583</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>828269</td>\n",
       "      <td>@AmazonHelp</td>\n",
       "      <td>[':face_with_tears_of_joy:']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>8007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id          text                     emoticons\n",
       "count     29713         29713                         29713\n",
       "unique    29713         29583                            55\n",
       "top      828269  @AmazonHelp   [':face_with_tears_of_joy:']\n",
       "freq          1            24                          8007"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each tweet's text was read as a string, which makes sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <class 'str'>\n",
       "1    <class 'str'>\n",
       "2    <class 'str'>\n",
       "3    <class 'str'>\n",
       "4    <class 'str'>\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()[TWEET_COL].apply(type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each tweet's list of emojis was read as one big string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <class 'str'>\n",
       "1    <class 'str'>\n",
       "2    <class 'str'>\n",
       "3    <class 'str'>\n",
       "4    <class 'str'>\n",
       "Name: emoticons, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()[EMOJI_COL].apply(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[':angry_face:']\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1, EMOJI_COL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, what we want is a list of emojis. Apply `ast.literal_eval()` to convert each emoji-list-string to an actual list of emoji strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['emoji_list'] = df[EMOJI_COL].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':angry_face:']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1, 'emoji_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [:face_with_tears_of_joy:]\n",
       "1                [:angry_face:]\n",
       "2             [:thinking_face:]\n",
       "3             [:thinking_face:]\n",
       "4               [:green_heart:]\n",
       "5    [:face_with_tears_of_joy:]\n",
       "6               [:green_heart:]\n",
       "7    [:face_with_rolling_eyes:]\n",
       "8    [:face_with_rolling_eyes:]\n",
       "9               [:thumbs_down:]\n",
       "Name: emoji_list, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emoji_list'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Plot the distribution of tweet lengths\n",
    "### What are the min/max/mean lengths? Do these make sense from what you know about tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emojis per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### What is the distribution of Emojis per tweet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweets per emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### What emojis appear in the dataset?\n",
    "### With what frequency do they appear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train & validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22284 22284\n",
      "7429 7429\n"
     ]
    }
   ],
   "source": [
    "tweets_train, tweets_eval, emojis_train, emojis_eval = train_test_split(\n",
    "    df[TWEET_COL].tolist(),\n",
    "    df['emoji_list'].tolist(),\n",
    "    random_state=12\n",
    ")\n",
    "print(len(tweets_train), len(emojis_train))\n",
    "print(len(tweets_eval), len(emojis_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each tweet has a list of one or more emojis that appeared in it. Convert each emoji list to True/False dummy values (one for each emoji) indicating which emojis appeared\n",
    "Note: We only need this for the train dataset, so eval & test are ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Hard-coded with 3 emojis - but you might want to extend to include all unique emojis in the dataset \n",
    "\n",
    "distinct_emojis = [':face_with_tears_of_joy:', ':thumbs_down:', ':smiling_face:']\n",
    "\n",
    "n_emojis = len(distinct_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22284, 3)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dummify_emojis(emojis):\n",
    "    emoji_set = set(emojis)\n",
    "    return [emoji in emoji_set for emoji in distinct_emojis]\n",
    "emoji_dummies_train = np.array([dummify_emojis(emojis) for emojis in emojis_train])\n",
    "emoji_dummies_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':face_with_rolling_eyes:']:\t[False False False]\n",
      "[':face_with_tears_of_joy:']:\t[ True False False]\n",
      "[':face_with_rolling_eyes:']:\t[False False False]\n",
      "[':smiling_face:']:\t[False False  True]\n",
      "[':face_with_rolling_eyes:']:\t[False False False]\n",
      "[':thinking_face:']:\t[False False False]\n",
      "[':face_with_tears_of_joy:']:\t[ True False False]\n",
      "[':thumbs_down:']:\t[False  True False]\n",
      "[':smiling_face_with_heart-eyes:']:\t[False False False]\n",
      "[':smiling_face:']:\t[False False  True]\n"
     ]
    }
   ],
   "source": [
    "for i, emoji_tweet in enumerate(emojis_train[:10]):\n",
    "    print(str(emoji_tweet) + \":\\t\" + str(emoji_dummies_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ^ This array contains the training targets for our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM Approach\n",
    "\n",
    "Gradient Boosting Model (GBM) = ensemble of decision trees:\n",
    "![](gbm.png)\n",
    "\n",
    "- This baseline modeling approach uses 3 GBMs (one for each sample emoji) to predict if its respective emoji appears in a given tweet.\n",
    "- For each tweet, all 3 GBMs will output some probability between 0 and 1.\n",
    "- These 3 outputs must be used to determine which emojis to predict belong with the tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert each tweet's text to feature vectors\n",
    "\n",
    "This is the biggest NLP-y step. We need to convert raw text of each tweet to a set of structured features that a modeling algorithm can learn from. To accomplish that, `sklearn`'s `CountVectorizer` is used here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class can handle:\n",
    "\n",
    "- Tokenization\n",
    " - Splitting each tweet string into \"tokens\" (basically a list of words)\n",
    "- n-grams\n",
    " - Pairs of two words that appear in sequence (bi-grams), three words (tri-grams), etc.\n",
    "- Dropping stop words\n",
    " - Words that appear very frequently and don't mean much for our prediction task, e.g. \"the\", \"a\", etc.\n",
    "- Lowercasing\n",
    " - Ignores the difference between \"The\" and \"the\", e.g.\n",
    "- And more\n",
    " - See the docs for all options: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "Finally, it counts the number of times each token appears in each tweet, and returns a sparse matrix of the token counts for each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22284x36529 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 360452 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_vectors_train = vectorizer.fit_transform(tweets_train)\n",
    "tweet_vectors_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7429x36529 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 112459 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_vectors_eval = vectorizer.transform(tweets_eval)\n",
    "tweet_vectors_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ^ These sparse matrixes are the input feature values for our GBM models\n",
    "- Most values in each matrix are 0, since any given tweet only uses a small subset of the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are now ready to train the GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fit_emoji_i_gbm(i):\n",
    "    X = tweet_vectors_train\n",
    "    y = emoji_dummies_train[:, i]\n",
    "    gbm = GradientBoostingClassifier()\n",
    "    gbm.fit(X, y)\n",
    "    return gbm\n",
    "gbms = Pool(n_emojis).map(fit_emoji_i_gbm, range(n_emojis))\n",
    "len(gbms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "               presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "               warm_start=False),\n",
       " GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "               presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "               warm_start=False),\n",
       " GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "               presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "               warm_start=False)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With training complete, call each model's  `predict_proba` on the validation sample to get 15 emoji probabilities for each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7429, 3)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_probas(gbm, tweet_vectors):\n",
    "    X = tweet_vectors\n",
    "    cls_probas = gbm.predict_proba(X)\n",
    "    pos_cls_ix = gbm.classes_.argmax()\n",
    "    pos_cls_probas = cls_probas[:, pos_cls_ix]\n",
    "    return pos_cls_probas\n",
    "\n",
    "emoji_probas_eval = np.array([predict_probas(gbm, tweet_vectors_eval) for gbm in gbms])\n",
    "emoji_probas_eval = emoji_probas_eval.T  # transpose probas from by-emoji to by-tweet\n",
    "emoji_probas_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42524449,  0.063263  ,  0.06133028],\n",
       "       [ 0.13776286,  0.04504414,  0.03926895]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_probas_eval[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Emojis for each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7429"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_emojis(emoji_probas, threshold=0.5):\n",
    "    emojis_pred = [emoji for emoji, emoji_proba in zip(distinct_emojis, emoji_probas) if emoji_proba > threshold]\n",
    "    if emojis_pred:\n",
    "        return emojis_pred\n",
    "    else:\n",
    "        max_proba_emoji_ix = np.argmax(emoji_probas)\n",
    "        return [distinct_emojis[max_proba_emoji_ix]]\n",
    "\n",
    "emoji_preds_eval = [predict_emojis(emoji_probas) for emoji_probas in emoji_probas_eval]\n",
    "len(emoji_preds_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[':face_with_tears_of_joy:'],\n",
       " [':face_with_tears_of_joy:'],\n",
       " [':face_with_tears_of_joy:'],\n",
       " [':face_with_tears_of_joy:'],\n",
       " [':smiling_face:'],\n",
       " [':face_with_tears_of_joy:'],\n",
       " [':face_with_tears_of_joy:'],\n",
       " [':face_with_tears_of_joy:'],\n",
       " [':face_with_tears_of_joy:'],\n",
       " [':face_with_tears_of_joy:']]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_preds_eval[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the emoji predictions against the true emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tweets: 7429\n",
      "score: 0.2779647328038767\n"
     ]
    }
   ],
   "source": [
    "def score_preds(emojis_true, emojis_pred):\n",
    "    def score_1(trues, preds):\n",
    "        trues = set(trues)\n",
    "        preds = set(preds)\n",
    "        n_correct = len(trues.intersection(preds))\n",
    "        score = n_correct/ max(len(trues), len(preds))\n",
    "        return score\n",
    "    scores = [score_1(trues, preds)\n",
    "              for trues, preds in zip(emojis_true, emojis_pred)]\n",
    "    mean_score = sum(scores) / len(scores)\n",
    "    print('# tweets:', len(scores))\n",
    "    print('score:', mean_score)\n",
    "\n",
    "score_preds(emojis_eval, emoji_preds_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understand the baseline model\n",
    "\n",
    "Questions you might want to think about, or ask a friendly drop-in face!\n",
    "\n",
    "* What is a GBM model?\n",
    "* What are the Features in this model?\n",
    "* What are the Targets in this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Improve the model!\n",
    "\n",
    "- Hand craft features\n",
    "  - Use the @<user> handles\n",
    "    - Is there a correlation between the number of handles used and the number of emojis?\n",
    "  - Any rules, i.e. `'love'` -> `':heart:'`?\n",
    "  - Are any of the train tweets duplicated in the test set?\n",
    "- Tuning the GBM parameters\n",
    "- Optimize the emoji probability to prediction function\n",
    "  - Maximize expected points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
